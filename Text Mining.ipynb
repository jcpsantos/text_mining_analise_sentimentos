{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Text Mining</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noticia</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diretor petrobras nega organização criminosa e...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tom cauteloso janet yellen pressiona bolsas f...</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bovespa caminha nova máxima ano quarta alta s...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>após abrir estável ibovespa passa registrar q...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paulo miranda reivindica iluminação telefonia...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             noticia sentimento\n",
       "0  diretor petrobras nega organização criminosa e...   positivo\n",
       "1   tom cauteloso janet yellen pressiona bolsas f...     neutro\n",
       "2   bovespa caminha nova máxima ano quarta alta s...   positivo\n",
       "3   após abrir estável ibovespa passa registrar q...   negativo\n",
       "4   paulo miranda reivindica iluminação telefonia...   positivo"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ler arquivo de dados\n",
    "ds = pd.read_csv('titulo_noticias.txt',encoding='utf-8')\n",
    "ds.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizando a distribuição de classes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x203d80f2198>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ds.sentimento.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando o primeiro modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pip_simples = Pipeline([\n",
    "  ('counts', CountVectorizer()),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para fazer a avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avalia_modelo(clf, X, y):\n",
    "    resultados = cross_val_predict(clf, X, y, cv=5)\n",
    "    print (pd.crosstab(y, resultados, rownames=['Real'], colnames=['Predito'], margins=True))\n",
    "    return np.mean(cross_val_score(clf, X, y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliar nosso primeiro modelo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito     negativo   neutro   positivo   All\n",
      "Real                                          \n",
      " negativo        531       39        176   746\n",
      " neutro          103      142        207   452\n",
      " positivo        111       63        751   925\n",
      "All              745      244       1134  2123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6707639451209663"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avalia_modelo(pip_simples,ds.noticia,ds.sentimento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos um modelo com 67% de acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo com Tag de Negações**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que irá atribuir uma tag (_NEG) as palavras após encontrar um ‘não’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marque_negacao(texto):\n",
    "    negacoes = ['não','not']\n",
    "    negacao_detectada = False\n",
    "    resultado = []\n",
    "    palavras = texto.split()\n",
    "    for p in palavras:\n",
    "        p = p.lower()\n",
    "        if negacao_detectada == True:\n",
    "            p = p + '_NEG'\n",
    "        if p in negacoes:\n",
    "            negacao_detectada = True\n",
    "        resultado.append(p)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver como funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'gosto', 'do', 'brasil']\n",
      "['eu', 'não', 'gosto_NEG', 'do_NEG', 'brasil_NEG']\n"
     ]
    }
   ],
   "source": [
    "print (marque_negacao('Eu gosto do Brasil'))\n",
    "print (marque_negacao('Eu não gosto do Brasil'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline que irá fazer uso dessa função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_neg = Pipeline([\n",
    "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliar o modelo usando essa configuração de negações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito     negativo   neutro   positivo   All\n",
      "Real                                          \n",
      " negativo        520       43        183   746\n",
      " neutro          105      142        205   452\n",
      " positivo        115       64        746   925\n",
      "All              740      249       1134  2123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6632311724583536"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avalia_modelo(pip_neg,ds.noticia,ds.sentimento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos um modelo com 66% de acurácia, esse modelo teve uma acurácia menor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando novas Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe que usaremos para fazer o processamento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class QtdPalavras(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def tamanho_noticia(self, texto):\n",
    "        return len(texto.split())\n",
    "    \n",
    "    def transform(self, news, y=None):\n",
    "        vet_tam = []\n",
    "        vet_tam_2 = []\n",
    "        for n in news:\n",
    "            vet_tam.append(self.tamanho_noticia(n))\n",
    "        vet_tam_2 = [[i] for i in vet_tam]\n",
    "        return vet_tam_2\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria o objeto do tipo FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "features = FeatureUnion([('QuantidadePalavras',QtdPalavras())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noticia</th>\n",
       "      <th>sentimento</th>\n",
       "      <th>qtd_palavras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diretor petrobras nega organização criminosa e...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tom cauteloso janet yellen pressiona bolsas f...</td>\n",
       "      <td>neutro</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bovespa caminha nova máxima ano quarta alta s...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>após abrir estável ibovespa passa registrar q...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paulo miranda reivindica iluminação telefonia...</td>\n",
       "      <td>positivo</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             noticia sentimento  qtd_palavras\n",
       "0  diretor petrobras nega organização criminosa e...   positivo             8\n",
       "1   tom cauteloso janet yellen pressiona bolsas f...     neutro             8\n",
       "2   bovespa caminha nova máxima ano quarta alta s...   positivo             8\n",
       "3   após abrir estável ibovespa passa registrar q...   negativo             9\n",
       "4   paulo miranda reivindica iluminação telefonia...   positivo             7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds['qtd_palavras'] = features.fit_transform(ds.noticia,ds.sentimento)\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.drop(['qtd_palavras'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipelining…**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar o pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2123x3803 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17325 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_process = Pipeline([\n",
    "                ('count', CountVectorizer())\n",
    "            ])\n",
    "text_process.fit_transform(ds.noticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline que irá fazer o processamento da quantidade de palavras de cada título."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8],\n",
       " [8],\n",
       " [8],\n",
       " [9],\n",
       " [7],\n",
       " [8],\n",
       " [10],\n",
       " [7],\n",
       " [10],\n",
       " [6],\n",
       " [9],\n",
       " [14],\n",
       " [11],\n",
       " [8],\n",
       " [15],\n",
       " [7],\n",
       " [6],\n",
       " [10],\n",
       " [11],\n",
       " [6],\n",
       " [9],\n",
       " [11],\n",
       " [7],\n",
       " [7],\n",
       " [10],\n",
       " [7],\n",
       " [9],\n",
       " [10],\n",
       " [10],\n",
       " [5],\n",
       " [5],\n",
       " [8],\n",
       " [7],\n",
       " [7],\n",
       " [10],\n",
       " [7],\n",
       " [8],\n",
       " [10],\n",
       " [6],\n",
       " [11],\n",
       " [10],\n",
       " [8],\n",
       " [6],\n",
       " [7],\n",
       " [10],\n",
       " [9],\n",
       " [8],\n",
       " [9],\n",
       " [7],\n",
       " [6],\n",
       " [8],\n",
       " [8],\n",
       " [9],\n",
       " [9],\n",
       " [4],\n",
       " [14],\n",
       " [9],\n",
       " [13],\n",
       " [8],\n",
       " [9],\n",
       " [11],\n",
       " [6],\n",
       " [6],\n",
       " [4],\n",
       " [9],\n",
       " [4],\n",
       " [10],\n",
       " [7],\n",
       " [2],\n",
       " [7],\n",
       " [12],\n",
       " [6],\n",
       " [9],\n",
       " [9],\n",
       " [10],\n",
       " [8],\n",
       " [6],\n",
       " [7],\n",
       " [12],\n",
       " [10],\n",
       " [6],\n",
       " [11],\n",
       " [4],\n",
       " [13],\n",
       " [8],\n",
       " [7],\n",
       " [6],\n",
       " [9],\n",
       " [8],\n",
       " [7],\n",
       " [10],\n",
       " [12],\n",
       " [3],\n",
       " [10],\n",
       " [7],\n",
       " [8],\n",
       " [7],\n",
       " [6],\n",
       " [7],\n",
       " [11],\n",
       " [10],\n",
       " [7],\n",
       " [5],\n",
       " [5],\n",
       " [8],\n",
       " [7],\n",
       " [9],\n",
       " [7],\n",
       " [7],\n",
       " [5],\n",
       " [10],\n",
       " [15],\n",
       " [8],\n",
       " [8],\n",
       " [11],\n",
       " [6],\n",
       " [6],\n",
       " [2],\n",
       " [7],\n",
       " [5],\n",
       " [9],\n",
       " [7],\n",
       " [2],\n",
       " [7],\n",
       " [5],\n",
       " [7],\n",
       " [8],\n",
       " [7],\n",
       " [11],\n",
       " [8],\n",
       " [4],\n",
       " [8],\n",
       " [8],\n",
       " [6],\n",
       " [11],\n",
       " [9],\n",
       " [7],\n",
       " [6],\n",
       " [9],\n",
       " [6],\n",
       " [7],\n",
       " [13],\n",
       " [10],\n",
       " [4],\n",
       " [10],\n",
       " [9],\n",
       " [12],\n",
       " [7],\n",
       " [7],\n",
       " [9],\n",
       " [8],\n",
       " [12],\n",
       " [10],\n",
       " [8],\n",
       " [11],\n",
       " [9],\n",
       " [9],\n",
       " [9],\n",
       " [5],\n",
       " [9],\n",
       " [10],\n",
       " [8],\n",
       " [8],\n",
       " [9],\n",
       " [12],\n",
       " [6],\n",
       " [8],\n",
       " [8],\n",
       " [6],\n",
       " [13],\n",
       " [8],\n",
       " [7],\n",
       " [7],\n",
       " [11],\n",
       " [5],\n",
       " [6],\n",
       " [5],\n",
       " [8],\n",
       " [5],\n",
       " [4],\n",
       " [5],\n",
       " [9],\n",
       " [8],\n",
       " [7],\n",
       " [11],\n",
       " [6],\n",
       " [2],\n",
       " [6],\n",
       " [10],\n",
       " [7],\n",
       " [12],\n",
       " [12],\n",
       " [12],\n",
       " [5],\n",
       " [9],\n",
       " [7],\n",
       " [5],\n",
       " [11],\n",
       " [10],\n",
       " [12],\n",
       " [9],\n",
       " [6],\n",
       " [7],\n",
       " [9],\n",
       " [11],\n",
       " [9],\n",
       " [10],\n",
       " [7],\n",
       " [8],\n",
       " [10],\n",
       " [8],\n",
       " [8],\n",
       " [10],\n",
       " [6],\n",
       " [7],\n",
       " [7],\n",
       " [11],\n",
       " [9],\n",
       " [12],\n",
       " [9],\n",
       " [6],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [8],\n",
       " [5],\n",
       " [10],\n",
       " [9],\n",
       " [7],\n",
       " [9],\n",
       " [9],\n",
       " [6],\n",
       " [8],\n",
       " [11],\n",
       " [8],\n",
       " [6],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [5],\n",
       " [11],\n",
       " [10],\n",
       " [12],\n",
       " [6],\n",
       " [11],\n",
       " [8],\n",
       " [6],\n",
       " [10],\n",
       " [8],\n",
       " [6],\n",
       " [7],\n",
       " [6],\n",
       " [10],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [6],\n",
       " [9],\n",
       " [9],\n",
       " [10],\n",
       " [7],\n",
       " [6],\n",
       " [9],\n",
       " [10],\n",
       " [9],\n",
       " [9],\n",
       " [10],\n",
       " [6],\n",
       " [12],\n",
       " [7],\n",
       " [9],\n",
       " [7],\n",
       " [9],\n",
       " [9],\n",
       " [8],\n",
       " [9],\n",
       " [6],\n",
       " [7],\n",
       " [3],\n",
       " [8],\n",
       " [6],\n",
       " [8],\n",
       " [10],\n",
       " [6],\n",
       " [7],\n",
       " [4],\n",
       " [6],\n",
       " [8],\n",
       " [9],\n",
       " [12],\n",
       " [9],\n",
       " [10],\n",
       " [5],\n",
       " [11],\n",
       " [8],\n",
       " [9],\n",
       " [7],\n",
       " [6],\n",
       " [9],\n",
       " [8],\n",
       " [11],\n",
       " [8],\n",
       " [11],\n",
       " [9],\n",
       " [7],\n",
       " [10],\n",
       " [8],\n",
       " [5],\n",
       " [9],\n",
       " [9],\n",
       " [11],\n",
       " [10],\n",
       " [8],\n",
       " [5],\n",
       " [9],\n",
       " [8],\n",
       " [12],\n",
       " [10],\n",
       " [11],\n",
       " [10],\n",
       " [9],\n",
       " [10],\n",
       " [8],\n",
       " [8],\n",
       " [5],\n",
       " [10],\n",
       " [9],\n",
       " [10],\n",
       " [7],\n",
       " [9],\n",
       " [6],\n",
       " [9],\n",
       " [10],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [9],\n",
       " [6],\n",
       " [9],\n",
       " [10],\n",
       " [10],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [4],\n",
       " [7],\n",
       " [10],\n",
       " [7],\n",
       " [8],\n",
       " [4],\n",
       " [6],\n",
       " [8],\n",
       " [8],\n",
       " [10],\n",
       " [8],\n",
       " [6],\n",
       " [9],\n",
       " [12],\n",
       " [11],\n",
       " [10],\n",
       " [8],\n",
       " [8],\n",
       " [7],\n",
       " [5],\n",
       " [6],\n",
       " [10],\n",
       " [5],\n",
       " [8],\n",
       " [8],\n",
       " [7],\n",
       " [9],\n",
       " [5],\n",
       " [10],\n",
       " [8],\n",
       " [9],\n",
       " [8],\n",
       " [6],\n",
       " [9],\n",
       " [11],\n",
       " [5],\n",
       " [10],\n",
       " [9],\n",
       " [8],\n",
       " [9],\n",
       " [10],\n",
       " [9],\n",
       " [11],\n",
       " [8],\n",
       " [10],\n",
       " [5],\n",
       " [9],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [8],\n",
       " [8],\n",
       " [11],\n",
       " [7],\n",
       " [5],\n",
       " [8],\n",
       " [12],\n",
       " [9],\n",
       " [12],\n",
       " [12],\n",
       " [10],\n",
       " [6],\n",
       " [8],\n",
       " [6],\n",
       " [9],\n",
       " [7],\n",
       " [18],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [5],\n",
       " [7],\n",
       " [14],\n",
       " [14],\n",
       " [10],\n",
       " [5],\n",
       " [11],\n",
       " [8],\n",
       " [9],\n",
       " [9],\n",
       " [13],\n",
       " [5],\n",
       " [11],\n",
       " [9],\n",
       " [6],\n",
       " [8],\n",
       " [7],\n",
       " [11],\n",
       " [10],\n",
       " [4],\n",
       " [5],\n",
       " [5],\n",
       " [10],\n",
       " [9],\n",
       " [8],\n",
       " [6],\n",
       " [10],\n",
       " [7],\n",
       " [7],\n",
       " [6],\n",
       " [10],\n",
       " [7],\n",
       " [8],\n",
       " [7],\n",
       " [8],\n",
       " [5],\n",
       " [5],\n",
       " [9],\n",
       " [7],\n",
       " [4],\n",
       " [5],\n",
       " [4],\n",
       " [5],\n",
       " [6],\n",
       " [9],\n",
       " [5],\n",
       " [10],\n",
       " [9],\n",
       " [9],\n",
       " [9],\n",
       " [8],\n",
       " [11],\n",
       " [10],\n",
       " [9],\n",
       " [9],\n",
       " [6],\n",
       " [9],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [10],\n",
       " [6],\n",
       " [6],\n",
       " [10],\n",
       " [12],\n",
       " [11],\n",
       " [6],\n",
       " [9],\n",
       " [7],\n",
       " [6],\n",
       " [10],\n",
       " [7],\n",
       " [13],\n",
       " [7],\n",
       " [9],\n",
       " [9],\n",
       " [6],\n",
       " [6],\n",
       " [11],\n",
       " [7],\n",
       " [8],\n",
       " [10],\n",
       " [11],\n",
       " [9],\n",
       " [7],\n",
       " [10],\n",
       " [12],\n",
       " [8],\n",
       " [6],\n",
       " [6],\n",
       " [8],\n",
       " [9],\n",
       " [5],\n",
       " [7],\n",
       " [10],\n",
       " [9],\n",
       " [11],\n",
       " [7],\n",
       " [8],\n",
       " [8],\n",
       " [10],\n",
       " [4],\n",
       " [6],\n",
       " [7],\n",
       " [9],\n",
       " [6],\n",
       " [10],\n",
       " [3],\n",
       " [8],\n",
       " [6],\n",
       " [8],\n",
       " [11],\n",
       " [9],\n",
       " [7],\n",
       " [8],\n",
       " [7],\n",
       " [13],\n",
       " [5],\n",
       " [6],\n",
       " [9],\n",
       " [9],\n",
       " [8],\n",
       " [4],\n",
       " [12],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [10],\n",
       " [2],\n",
       " [5],\n",
       " [8],\n",
       " [8],\n",
       " [12],\n",
       " [8],\n",
       " [6],\n",
       " [7],\n",
       " [4],\n",
       " [7],\n",
       " [6],\n",
       " [12],\n",
       " [9],\n",
       " [9],\n",
       " [11],\n",
       " [9],\n",
       " [10],\n",
       " [8],\n",
       " [8],\n",
       " [15],\n",
       " [6],\n",
       " [8],\n",
       " [7],\n",
       " [11],\n",
       " [8],\n",
       " [6],\n",
       " [9],\n",
       " [5],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [8],\n",
       " [10],\n",
       " [6],\n",
       " [12],\n",
       " [4],\n",
       " [5],\n",
       " [5],\n",
       " [8],\n",
       " [7],\n",
       " [5],\n",
       " [11],\n",
       " [9],\n",
       " [8],\n",
       " [10],\n",
       " [10],\n",
       " [4],\n",
       " [11],\n",
       " [7],\n",
       " [12],\n",
       " [10],\n",
       " [9],\n",
       " [6],\n",
       " [8],\n",
       " [8],\n",
       " [8],\n",
       " [6],\n",
       " [11],\n",
       " [20],\n",
       " [5],\n",
       " [10],\n",
       " [10],\n",
       " [7],\n",
       " [8],\n",
       " [12],\n",
       " [10],\n",
       " [12],\n",
       " [12],\n",
       " [4],\n",
       " [11],\n",
       " [8],\n",
       " [5],\n",
       " [8],\n",
       " [9],\n",
       " [10],\n",
       " [9],\n",
       " [6],\n",
       " [4],\n",
       " [5],\n",
       " [1],\n",
       " [10],\n",
       " [5],\n",
       " [11],\n",
       " [10],\n",
       " [7],\n",
       " [9],\n",
       " [6],\n",
       " [7],\n",
       " [12],\n",
       " [5],\n",
       " [9],\n",
       " [7],\n",
       " [8],\n",
       " [8],\n",
       " [13],\n",
       " [8],\n",
       " [9],\n",
       " [8],\n",
       " [10],\n",
       " [7],\n",
       " [8],\n",
       " [14],\n",
       " [11],\n",
       " [7],\n",
       " [11],\n",
       " [10],\n",
       " [9],\n",
       " [6],\n",
       " [9],\n",
       " [10],\n",
       " [6],\n",
       " [13],\n",
       " [8],\n",
       " [7],\n",
       " [8],\n",
       " [7],\n",
       " [6],\n",
       " [8],\n",
       " [7],\n",
       " [6],\n",
       " [7],\n",
       " [6],\n",
       " [12],\n",
       " [7],\n",
       " [9],\n",
       " [2],\n",
       " [7],\n",
       " [9],\n",
       " [8],\n",
       " [12],\n",
       " [11],\n",
       " [3],\n",
       " [10],\n",
       " [14],\n",
       " [11],\n",
       " [5],\n",
       " [11],\n",
       " [5],\n",
       " [7],\n",
       " [10],\n",
       " [9],\n",
       " [7],\n",
       " [11],\n",
       " [11],\n",
       " [7],\n",
       " [9],\n",
       " [8],\n",
       " [7],\n",
       " [9],\n",
       " [8],\n",
       " [13],\n",
       " [5],\n",
       " [10],\n",
       " [8],\n",
       " [11],\n",
       " [10],\n",
       " [8],\n",
       " [2],\n",
       " [11],\n",
       " [8],\n",
       " [9],\n",
       " [8],\n",
       " [8],\n",
       " [7],\n",
       " [13],\n",
       " [6],\n",
       " [11],\n",
       " [8],\n",
       " [13],\n",
       " [8],\n",
       " [9],\n",
       " [10],\n",
       " [8],\n",
       " [9],\n",
       " [8],\n",
       " [7],\n",
       " [7],\n",
       " [6],\n",
       " [5],\n",
       " [5],\n",
       " [6],\n",
       " [8],\n",
       " [7],\n",
       " [8],\n",
       " [3],\n",
       " [5],\n",
       " [11],\n",
       " [11],\n",
       " [8],\n",
       " [8],\n",
       " [9],\n",
       " [10],\n",
       " [8],\n",
       " [10],\n",
       " [9],\n",
       " [8],\n",
       " [9],\n",
       " [7],\n",
       " [8],\n",
       " [9],\n",
       " [12],\n",
       " [6],\n",
       " [9],\n",
       " [8],\n",
       " [10],\n",
       " [6],\n",
       " [9],\n",
       " [6],\n",
       " [10],\n",
       " [9],\n",
       " [10],\n",
       " [8],\n",
       " [4],\n",
       " [8],\n",
       " [11],\n",
       " [8],\n",
       " [7],\n",
       " [9],\n",
       " [9],\n",
       " [9],\n",
       " [12],\n",
       " [7],\n",
       " [8],\n",
       " [7],\n",
       " [10],\n",
       " [10],\n",
       " [8],\n",
       " [7],\n",
       " [10],\n",
       " [5],\n",
       " [8],\n",
       " [4],\n",
       " [6],\n",
       " [9],\n",
       " [11],\n",
       " [3],\n",
       " [5],\n",
       " [8],\n",
       " [11],\n",
       " [8],\n",
       " [8],\n",
       " [8],\n",
       " [4],\n",
       " [7],\n",
       " [7],\n",
       " [9],\n",
       " [5],\n",
       " [7],\n",
       " [5],\n",
       " [9],\n",
       " [11],\n",
       " [10],\n",
       " [7],\n",
       " [6],\n",
       " [8],\n",
       " [7],\n",
       " [10],\n",
       " [10],\n",
       " [5],\n",
       " [9],\n",
       " [5],\n",
       " [9],\n",
       " [8],\n",
       " [10],\n",
       " [17],\n",
       " [6],\n",
       " [10],\n",
       " [8],\n",
       " [10],\n",
       " [12],\n",
       " [12],\n",
       " [7],\n",
       " [6],\n",
       " [6],\n",
       " [8],\n",
       " [8],\n",
       " [9],\n",
       " [8],\n",
       " [11],\n",
       " [8],\n",
       " [9],\n",
       " [10],\n",
       " [8],\n",
       " [7],\n",
       " [10],\n",
       " [10],\n",
       " [13],\n",
       " [6],\n",
       " [5],\n",
       " [10],\n",
       " [2],\n",
       " [11],\n",
       " [7],\n",
       " [6],\n",
       " [12],\n",
       " [10],\n",
       " [9],\n",
       " [9],\n",
       " [8],\n",
       " [9],\n",
       " [6],\n",
       " [10],\n",
       " [5],\n",
       " [6],\n",
       " [11],\n",
       " [9],\n",
       " [8],\n",
       " [6],\n",
       " [12],\n",
       " [9],\n",
       " [7],\n",
       " [13],\n",
       " [5],\n",
       " [9],\n",
       " [4],\n",
       " [9],\n",
       " [10],\n",
       " [13],\n",
       " [10],\n",
       " [12],\n",
       " [4],\n",
       " [7],\n",
       " [8],\n",
       " [8],\n",
       " [2],\n",
       " [5],\n",
       " [7],\n",
       " [8],\n",
       " [5],\n",
       " [7],\n",
       " [9],\n",
       " [10],\n",
       " [6],\n",
       " [6],\n",
       " [9],\n",
       " [6],\n",
       " [10],\n",
       " [11],\n",
       " [9],\n",
       " [5],\n",
       " [8],\n",
       " [6],\n",
       " [7],\n",
       " [11],\n",
       " [5],\n",
       " [8],\n",
       " [8],\n",
       " [10],\n",
       " [19],\n",
       " [8],\n",
       " [7],\n",
       " [5],\n",
       " [10],\n",
       " [9],\n",
       " [6],\n",
       " [14],\n",
       " [6],\n",
       " [9],\n",
       " [12],\n",
       " [11],\n",
       " [7],\n",
       " [9],\n",
       " [9],\n",
       " [10],\n",
       " [5],\n",
       " [10],\n",
       " [9],\n",
       " [6],\n",
       " [4],\n",
       " [16],\n",
       " [8],\n",
       " [8],\n",
       " [8],\n",
       " [5],\n",
       " [6],\n",
       " [8],\n",
       " [8],\n",
       " [10],\n",
       " [7],\n",
       " [7],\n",
       " [9],\n",
       " [9],\n",
       " [13],\n",
       " [6],\n",
       " [8],\n",
       " [8],\n",
       " [10],\n",
       " [6],\n",
       " [8],\n",
       " [8],\n",
       " [6],\n",
       " [12],\n",
       " [12],\n",
       " [4],\n",
       " [9],\n",
       " [8],\n",
       " [8],\n",
       " [6],\n",
       " [10],\n",
       " [11],\n",
       " [8],\n",
       " [8],\n",
       " [8],\n",
       " [8],\n",
       " [10],\n",
       " [9],\n",
       " [7],\n",
       " [6],\n",
       " [4],\n",
       " [9],\n",
       " [10],\n",
       " [8],\n",
       " [7],\n",
       " [7],\n",
       " [8],\n",
       " [17],\n",
       " [8],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [9],\n",
       " [3],\n",
       " [8],\n",
       " [6],\n",
       " [9],\n",
       " [8],\n",
       " [8],\n",
       " [10],\n",
       " [7],\n",
       " [6],\n",
       " [8],\n",
       " [10],\n",
       " [10],\n",
       " [8],\n",
       " [11],\n",
       " [8],\n",
       " [8],\n",
       " [11],\n",
       " [9],\n",
       " [10],\n",
       " [11],\n",
       " [6],\n",
       " [9],\n",
       " [4],\n",
       " [9],\n",
       " [7],\n",
       " [8],\n",
       " [6],\n",
       " [9],\n",
       " [8],\n",
       " [5],\n",
       " [7],\n",
       " [9],\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtd_palavras =  Pipeline([\n",
    "                ('qtd_palavras', QtdPalavras())\n",
    "            ])\n",
    "qtd_palavras.fit_transform(ds.noticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar o objeto FeatureUnion que faz a combinação dos pipelines text_process e qtd_palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureUnion([('text_process', text_process), \n",
    "                         ('qtd_palavras', qtd_palavras)\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text_process', Pipeline(memory=None,\n",
       "       steps=[('count', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None))])),\n",
       " ('qtd_palavras',\n",
       "  Pipeline(memory=None, steps=[('qtd_palavras', QtdPalavras())]))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.transformer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline pip_features_1 que contém o objeto FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text_process', Pipeline(memory=None,\n",
       "     steps=[('count', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_d...nsformer_weights=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip_features_1 = Pipeline([\n",
    "    ('features',features),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pip_features_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('features', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('text_process', Pipeline(memory=None,\n",
       "       steps=[('count', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_...abulary=None))])), ('qtd_palavras', Pipeline(memory=None, steps=[('qtd_palavras', QtdPalavras())]))],\n",
       "         transformer_weights=None)),\n",
       " ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip_features_1.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Vamos avaliar esse modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito     negativo   neutro   positivo   All\n",
      "Real                                          \n",
      " negativo        528       19        199   746\n",
      " neutro          104      111        237   452\n",
      " positivo        110       36        779   925\n",
      "All              742      166       1215  2123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6679393006205937"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avalia_modelo(pip_features_1,ds.noticia,ds.sentimento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando os resultados, vimos que esse modelo que contém a quantidade de palavras um pouco é pior que o modelo simples.\n",
    "\n",
    "Também perdeu 1% de acurácia.\n",
    "\n",
    "Porém, esse ficou melhor que o modelo que aplica as tags de negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantidade de Caracteres?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classe QtdCaracteres()\n",
    "\n",
    "Esta será a responsável por fazer o cálculo simples de contar a quantidade de caracteres de cada título."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class QtdPalavras(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def tamanho_noticia(self, texto):\n",
    "        return len(texto.split())\n",
    "    \n",
    "    def transform(self, news, y=None):\n",
    "        vet_tam = []\n",
    "        vet_tam_2 = []\n",
    "        for n in news:\n",
    "            vet_tam.append(self.tamanho_noticia(n))\n",
    "        vet_tam_2 = [[i] for i in vet_tam]\n",
    "        return vet_tam_2\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "class QtdCaracteres(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def conta_caracteres(self, texto):\n",
    "        return len(texto)\n",
    "    \n",
    "    def transform(self, news, y=None):\n",
    "        vet_tam = []\n",
    "        vet_tam_2 = []\n",
    "        for n in news:\n",
    "            vet_tam.append(self.conta_caracteres(n))\n",
    "        vet_tam_2 = [[i] for i in vet_tam]\n",
    "        return vet_tam_2\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline para combinar com as outras features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[69],\n",
       " [61],\n",
       " [53],\n",
       " [66],\n",
       " [58],\n",
       " [56],\n",
       " [76],\n",
       " [51],\n",
       " [68],\n",
       " [53],\n",
       " [69],\n",
       " [97],\n",
       " [75],\n",
       " [72],\n",
       " [107],\n",
       " [46],\n",
       " [47],\n",
       " [69],\n",
       " [78],\n",
       " [40],\n",
       " [63],\n",
       " [77],\n",
       " [65],\n",
       " [46],\n",
       " [74],\n",
       " [48],\n",
       " [51],\n",
       " [74],\n",
       " [74],\n",
       " [36],\n",
       " [41],\n",
       " [58],\n",
       " [51],\n",
       " [59],\n",
       " [83],\n",
       " [56],\n",
       " [64],\n",
       " [69],\n",
       " [65],\n",
       " [82],\n",
       " [78],\n",
       " [69],\n",
       " [47],\n",
       " [45],\n",
       " [70],\n",
       " [54],\n",
       " [58],\n",
       " [66],\n",
       " [60],\n",
       " [42],\n",
       " [57],\n",
       " [58],\n",
       " [61],\n",
       " [66],\n",
       " [30],\n",
       " [117],\n",
       " [70],\n",
       " [79],\n",
       " [54],\n",
       " [64],\n",
       " [67],\n",
       " [47],\n",
       " [47],\n",
       " [27],\n",
       " [74],\n",
       " [25],\n",
       " [71],\n",
       " [59],\n",
       " [15],\n",
       " [56],\n",
       " [77],\n",
       " [50],\n",
       " [56],\n",
       " [56],\n",
       " [67],\n",
       " [55],\n",
       " [47],\n",
       " [68],\n",
       " [90],\n",
       " [71],\n",
       " [46],\n",
       " [74],\n",
       " [31],\n",
       " [93],\n",
       " [64],\n",
       " [48],\n",
       " [53],\n",
       " [65],\n",
       " [51],\n",
       " [56],\n",
       " [72],\n",
       " [84],\n",
       " [26],\n",
       " [69],\n",
       " [47],\n",
       " [56],\n",
       " [61],\n",
       " [43],\n",
       " [57],\n",
       " [79],\n",
       " [74],\n",
       " [57],\n",
       " [43],\n",
       " [31],\n",
       " [68],\n",
       " [52],\n",
       " [73],\n",
       " [47],\n",
       " [50],\n",
       " [43],\n",
       " [69],\n",
       " [105],\n",
       " [54],\n",
       " [57],\n",
       " [77],\n",
       " [48],\n",
       " [41],\n",
       " [22],\n",
       " [52],\n",
       " [41],\n",
       " [70],\n",
       " [56],\n",
       " [13],\n",
       " [55],\n",
       " [45],\n",
       " [56],\n",
       " [67],\n",
       " [56],\n",
       " [70],\n",
       " [57],\n",
       " [36],\n",
       " [54],\n",
       " [57],\n",
       " [53],\n",
       " [71],\n",
       " [70],\n",
       " [56],\n",
       " [34],\n",
       " [69],\n",
       " [52],\n",
       " [61],\n",
       " [84],\n",
       " [79],\n",
       " [32],\n",
       " [83],\n",
       " [57],\n",
       " [92],\n",
       " [62],\n",
       " [55],\n",
       " [70],\n",
       " [61],\n",
       " [83],\n",
       " [78],\n",
       " [54],\n",
       " [92],\n",
       " [75],\n",
       " [61],\n",
       " [72],\n",
       " [41],\n",
       " [62],\n",
       " [87],\n",
       " [53],\n",
       " [60],\n",
       " [66],\n",
       " [91],\n",
       " [46],\n",
       " [64],\n",
       " [43],\n",
       " [49],\n",
       " [90],\n",
       " [59],\n",
       " [58],\n",
       " [55],\n",
       " [80],\n",
       " [47],\n",
       " [52],\n",
       " [30],\n",
       " [58],\n",
       " [40],\n",
       " [25],\n",
       " [42],\n",
       " [68],\n",
       " [59],\n",
       " [56],\n",
       " [79],\n",
       " [50],\n",
       " [12],\n",
       " [44],\n",
       " [70],\n",
       " [57],\n",
       " [90],\n",
       " [78],\n",
       " [70],\n",
       " [34],\n",
       " [66],\n",
       " [51],\n",
       " [37],\n",
       " [84],\n",
       " [81],\n",
       " [89],\n",
       " [71],\n",
       " [42],\n",
       " [58],\n",
       " [70],\n",
       " [82],\n",
       " [66],\n",
       " [79],\n",
       " [59],\n",
       " [73],\n",
       " [72],\n",
       " [60],\n",
       " [57],\n",
       " [66],\n",
       " [42],\n",
       " [37],\n",
       " [55],\n",
       " [92],\n",
       " [59],\n",
       " [79],\n",
       " [68],\n",
       " [47],\n",
       " [66],\n",
       " [46],\n",
       " [62],\n",
       " [66],\n",
       " [41],\n",
       " [74],\n",
       " [76],\n",
       " [54],\n",
       " [75],\n",
       " [68],\n",
       " [51],\n",
       " [57],\n",
       " [80],\n",
       " [64],\n",
       " [43],\n",
       " [32],\n",
       " [56],\n",
       " [43],\n",
       " [56],\n",
       " [58],\n",
       " [59],\n",
       " [56],\n",
       " [44],\n",
       " [80],\n",
       " [75],\n",
       " [80],\n",
       " [50],\n",
       " [82],\n",
       " [55],\n",
       " [50],\n",
       " [70],\n",
       " [66],\n",
       " [41],\n",
       " [51],\n",
       " [39],\n",
       " [77],\n",
       " [50],\n",
       " [66],\n",
       " [39],\n",
       " [55],\n",
       " [75],\n",
       " [67],\n",
       " [68],\n",
       " [62],\n",
       " [44],\n",
       " [66],\n",
       " [60],\n",
       " [75],\n",
       " [63],\n",
       " [74],\n",
       " [50],\n",
       " [87],\n",
       " [52],\n",
       " [59],\n",
       " [55],\n",
       " [78],\n",
       " [72],\n",
       " [66],\n",
       " [66],\n",
       " [50],\n",
       " [47],\n",
       " [21],\n",
       " [72],\n",
       " [48],\n",
       " [67],\n",
       " [71],\n",
       " [41],\n",
       " [58],\n",
       " [33],\n",
       " [53],\n",
       " [57],\n",
       " [79],\n",
       " [102],\n",
       " [72],\n",
       " [70],\n",
       " [39],\n",
       " [78],\n",
       " [62],\n",
       " [70],\n",
       " [63],\n",
       " [49],\n",
       " [73],\n",
       " [65],\n",
       " [90],\n",
       " [61],\n",
       " [79],\n",
       " [72],\n",
       " [51],\n",
       " [70],\n",
       " [63],\n",
       " [34],\n",
       " [67],\n",
       " [66],\n",
       " [82],\n",
       " [68],\n",
       " [65],\n",
       " [33],\n",
       " [80],\n",
       " [55],\n",
       " [88],\n",
       " [63],\n",
       " [82],\n",
       " [72],\n",
       " [69],\n",
       " [69],\n",
       " [52],\n",
       " [67],\n",
       " [42],\n",
       " [76],\n",
       " [63],\n",
       " [82],\n",
       " [51],\n",
       " [72],\n",
       " [47],\n",
       " [71],\n",
       " [88],\n",
       " [33],\n",
       " [52],\n",
       " [38],\n",
       " [71],\n",
       " [38],\n",
       " [71],\n",
       " [79],\n",
       " [79],\n",
       " [40],\n",
       " [38],\n",
       " [41],\n",
       " [37],\n",
       " [52],\n",
       " [66],\n",
       " [61],\n",
       " [72],\n",
       " [29],\n",
       " [46],\n",
       " [61],\n",
       " [67],\n",
       " [71],\n",
       " [69],\n",
       " [47],\n",
       " [67],\n",
       " [96],\n",
       " [80],\n",
       " [72],\n",
       " [70],\n",
       " [63],\n",
       " [54],\n",
       " [42],\n",
       " [42],\n",
       " [70],\n",
       " [37],\n",
       " [51],\n",
       " [63],\n",
       " [40],\n",
       " [75],\n",
       " [40],\n",
       " [77],\n",
       " [64],\n",
       " [74],\n",
       " [56],\n",
       " [51],\n",
       " [74],\n",
       " [89],\n",
       " [36],\n",
       " [73],\n",
       " [64],\n",
       " [49],\n",
       " [65],\n",
       " [65],\n",
       " [68],\n",
       " [76],\n",
       " [59],\n",
       " [82],\n",
       " [38],\n",
       " [71],\n",
       " [61],\n",
       " [57],\n",
       " [49],\n",
       " [48],\n",
       " [69],\n",
       " [67],\n",
       " [67],\n",
       " [47],\n",
       " [42],\n",
       " [70],\n",
       " [69],\n",
       " [81],\n",
       " [86],\n",
       " [85],\n",
       " [71],\n",
       " [50],\n",
       " [60],\n",
       " [39],\n",
       " [57],\n",
       " [52],\n",
       " [134],\n",
       " [78],\n",
       " [74],\n",
       " [77],\n",
       " [37],\n",
       " [58],\n",
       " [109],\n",
       " [102],\n",
       " [76],\n",
       " [35],\n",
       " [81],\n",
       " [66],\n",
       " [67],\n",
       " [79],\n",
       " [90],\n",
       " [40],\n",
       " [89],\n",
       " [70],\n",
       " [51],\n",
       " [63],\n",
       " [46],\n",
       " [82],\n",
       " [78],\n",
       " [39],\n",
       " [32],\n",
       " [43],\n",
       " [67],\n",
       " [62],\n",
       " [60],\n",
       " [44],\n",
       " [75],\n",
       " [47],\n",
       " [47],\n",
       " [47],\n",
       " [74],\n",
       " [56],\n",
       " [50],\n",
       " [53],\n",
       " [53],\n",
       " [41],\n",
       " [42],\n",
       " [66],\n",
       " [53],\n",
       " [38],\n",
       " [43],\n",
       " [31],\n",
       " [31],\n",
       " [52],\n",
       " [74],\n",
       " [40],\n",
       " [79],\n",
       " [68],\n",
       " [73],\n",
       " [60],\n",
       " [66],\n",
       " [79],\n",
       " [77],\n",
       " [68],\n",
       " [66],\n",
       " [42],\n",
       " [71],\n",
       " [40],\n",
       " [54],\n",
       " [37],\n",
       " [66],\n",
       " [43],\n",
       " [43],\n",
       " [71],\n",
       " [79],\n",
       " [76],\n",
       " [41],\n",
       " [84],\n",
       " [45],\n",
       " [49],\n",
       " [71],\n",
       " [57],\n",
       " [90],\n",
       " [63],\n",
       " [74],\n",
       " [74],\n",
       " [31],\n",
       " [52],\n",
       " [80],\n",
       " [56],\n",
       " [61],\n",
       " [76],\n",
       " [81],\n",
       " [80],\n",
       " [48],\n",
       " [73],\n",
       " [93],\n",
       " [60],\n",
       " [47],\n",
       " [47],\n",
       " [58],\n",
       " [64],\n",
       " [42],\n",
       " [53],\n",
       " [73],\n",
       " [75],\n",
       " [76],\n",
       " [54],\n",
       " [70],\n",
       " [52],\n",
       " [78],\n",
       " [33],\n",
       " [51],\n",
       " [55],\n",
       " [64],\n",
       " [45],\n",
       " [82],\n",
       " [18],\n",
       " [64],\n",
       " [35],\n",
       " [71],\n",
       " [71],\n",
       " [80],\n",
       " [51],\n",
       " [65],\n",
       " [53],\n",
       " [95],\n",
       " [31],\n",
       " [48],\n",
       " [61],\n",
       " [57],\n",
       " [58],\n",
       " [37],\n",
       " [89],\n",
       " [51],\n",
       " [41],\n",
       " [38],\n",
       " [74],\n",
       " [15],\n",
       " [44],\n",
       " [64],\n",
       " [62],\n",
       " [85],\n",
       " [53],\n",
       " [51],\n",
       " [50],\n",
       " [38],\n",
       " [36],\n",
       " [43],\n",
       " [78],\n",
       " [65],\n",
       " [73],\n",
       " [72],\n",
       " [73],\n",
       " [78],\n",
       " [49],\n",
       " [59],\n",
       " [113],\n",
       " [42],\n",
       " [58],\n",
       " [55],\n",
       " [72],\n",
       " [66],\n",
       " [43],\n",
       " [84],\n",
       " [36],\n",
       " [49],\n",
       " [58],\n",
       " [56],\n",
       " [56],\n",
       " [80],\n",
       " [41],\n",
       " [87],\n",
       " [37],\n",
       " [44],\n",
       " [38],\n",
       " [65],\n",
       " [64],\n",
       " [45],\n",
       " [79],\n",
       " [69],\n",
       " [59],\n",
       " [73],\n",
       " [76],\n",
       " [29],\n",
       " [76],\n",
       " [52],\n",
       " [76],\n",
       " [73],\n",
       " [63],\n",
       " [46],\n",
       " [75],\n",
       " [66],\n",
       " [54],\n",
       " [49],\n",
       " [71],\n",
       " [162],\n",
       " [32],\n",
       " [73],\n",
       " [75],\n",
       " [54],\n",
       " [58],\n",
       " [80],\n",
       " [63],\n",
       " [92],\n",
       " [88],\n",
       " [32],\n",
       " [91],\n",
       " [66],\n",
       " [43],\n",
       " [63],\n",
       " [88],\n",
       " [78],\n",
       " [70],\n",
       " [47],\n",
       " [35],\n",
       " [36],\n",
       " [7],\n",
       " [85],\n",
       " [46],\n",
       " [74],\n",
       " [71],\n",
       " [47],\n",
       " [67],\n",
       " [53],\n",
       " [51],\n",
       " [88],\n",
       " [38],\n",
       " [67],\n",
       " [51],\n",
       " [79],\n",
       " [59],\n",
       " [83],\n",
       " [70],\n",
       " [88],\n",
       " [60],\n",
       " [74],\n",
       " [53],\n",
       " [64],\n",
       " [106],\n",
       " [88],\n",
       " [59],\n",
       " [81],\n",
       " [69],\n",
       " [60],\n",
       " [46],\n",
       " [68],\n",
       " [72],\n",
       " [50],\n",
       " [102],\n",
       " [55],\n",
       " [51],\n",
       " [62],\n",
       " [47],\n",
       " [45],\n",
       " [65],\n",
       " [60],\n",
       " [44],\n",
       " [53],\n",
       " [48],\n",
       " [75],\n",
       " [44],\n",
       " [63],\n",
       " [14],\n",
       " [54],\n",
       " [64],\n",
       " [65],\n",
       " [88],\n",
       " [77],\n",
       " [31],\n",
       " [70],\n",
       " [116],\n",
       " [66],\n",
       " [50],\n",
       " [102],\n",
       " [29],\n",
       " [50],\n",
       " [70],\n",
       " [59],\n",
       " [53],\n",
       " [72],\n",
       " [78],\n",
       " [65],\n",
       " [67],\n",
       " [65],\n",
       " [51],\n",
       " [75],\n",
       " [64],\n",
       " [85],\n",
       " [40],\n",
       " [73],\n",
       " [61],\n",
       " [92],\n",
       " [76],\n",
       " [65],\n",
       " [19],\n",
       " [81],\n",
       " [56],\n",
       " [69],\n",
       " [68],\n",
       " [67],\n",
       " [49],\n",
       " [99],\n",
       " [40],\n",
       " [77],\n",
       " [62],\n",
       " [91],\n",
       " [71],\n",
       " [57],\n",
       " [90],\n",
       " [63],\n",
       " [69],\n",
       " [60],\n",
       " [58],\n",
       " [58],\n",
       " [46],\n",
       " [44],\n",
       " [42],\n",
       " [40],\n",
       " [70],\n",
       " [69],\n",
       " [57],\n",
       " [24],\n",
       " [42],\n",
       " [83],\n",
       " [76],\n",
       " [68],\n",
       " [62],\n",
       " [55],\n",
       " [73],\n",
       " [69],\n",
       " [74],\n",
       " [65],\n",
       " [67],\n",
       " [54],\n",
       " [57],\n",
       " [56],\n",
       " [61],\n",
       " [87],\n",
       " [49],\n",
       " [60],\n",
       " [63],\n",
       " [64],\n",
       " [45],\n",
       " [71],\n",
       " [49],\n",
       " [67],\n",
       " [53],\n",
       " [72],\n",
       " [51],\n",
       " [28],\n",
       " [60],\n",
       " [88],\n",
       " [73],\n",
       " [60],\n",
       " [66],\n",
       " [59],\n",
       " [59],\n",
       " [74],\n",
       " [52],\n",
       " [56],\n",
       " [52],\n",
       " [84],\n",
       " [74],\n",
       " [57],\n",
       " [53],\n",
       " [76],\n",
       " [36],\n",
       " [58],\n",
       " [33],\n",
       " [46],\n",
       " [67],\n",
       " [86],\n",
       " [24],\n",
       " [45],\n",
       " [51],\n",
       " [71],\n",
       " [50],\n",
       " [81],\n",
       " [72],\n",
       " [35],\n",
       " [56],\n",
       " [60],\n",
       " [62],\n",
       " [28],\n",
       " [51],\n",
       " [41],\n",
       " [68],\n",
       " [69],\n",
       " [75],\n",
       " [60],\n",
       " [61],\n",
       " [52],\n",
       " [67],\n",
       " [76],\n",
       " [76],\n",
       " [43],\n",
       " [58],\n",
       " [43],\n",
       " [60],\n",
       " [61],\n",
       " [83],\n",
       " [126],\n",
       " [44],\n",
       " [72],\n",
       " [66],\n",
       " [69],\n",
       " [88],\n",
       " [85],\n",
       " [50],\n",
       " [38],\n",
       " [48],\n",
       " [65],\n",
       " [56],\n",
       " [65],\n",
       " [65],\n",
       " [91],\n",
       " [66],\n",
       " [60],\n",
       " [77],\n",
       " [68],\n",
       " [58],\n",
       " [75],\n",
       " [73],\n",
       " [99],\n",
       " [54],\n",
       " [35],\n",
       " [73],\n",
       " [15],\n",
       " [76],\n",
       " [41],\n",
       " [47],\n",
       " [78],\n",
       " [75],\n",
       " [68],\n",
       " [79],\n",
       " [57],\n",
       " [71],\n",
       " [52],\n",
       " [67],\n",
       " [40],\n",
       " [43],\n",
       " [80],\n",
       " [76],\n",
       " [55],\n",
       " [43],\n",
       " [68],\n",
       " [61],\n",
       " [53],\n",
       " [89],\n",
       " [43],\n",
       " [63],\n",
       " [38],\n",
       " [76],\n",
       " [82],\n",
       " [78],\n",
       " [74],\n",
       " [82],\n",
       " [28],\n",
       " [54],\n",
       " [49],\n",
       " [64],\n",
       " [14],\n",
       " [46],\n",
       " [48],\n",
       " [68],\n",
       " [37],\n",
       " [50],\n",
       " [75],\n",
       " [73],\n",
       " [52],\n",
       " [47],\n",
       " [67],\n",
       " [45],\n",
       " [79],\n",
       " [85],\n",
       " [74],\n",
       " [37],\n",
       " [58],\n",
       " [46],\n",
       " [53],\n",
       " [79],\n",
       " [40],\n",
       " [66],\n",
       " [58],\n",
       " [72],\n",
       " [143],\n",
       " [53],\n",
       " [53],\n",
       " [34],\n",
       " [57],\n",
       " [68],\n",
       " [47],\n",
       " [93],\n",
       " [48],\n",
       " [69],\n",
       " [80],\n",
       " [83],\n",
       " [55],\n",
       " [62],\n",
       " [58],\n",
       " [78],\n",
       " [44],\n",
       " [70],\n",
       " [62],\n",
       " [52],\n",
       " [38],\n",
       " [97],\n",
       " [59],\n",
       " [59],\n",
       " [60],\n",
       " [48],\n",
       " [48],\n",
       " [41],\n",
       " [64],\n",
       " [68],\n",
       " [56],\n",
       " [36],\n",
       " [61],\n",
       " [60],\n",
       " [105],\n",
       " [46],\n",
       " [58],\n",
       " [67],\n",
       " [70],\n",
       " [51],\n",
       " [76],\n",
       " [65],\n",
       " [49],\n",
       " [83],\n",
       " [91],\n",
       " [38],\n",
       " [79],\n",
       " [61],\n",
       " [56],\n",
       " [43],\n",
       " [75],\n",
       " [73],\n",
       " [64],\n",
       " [71],\n",
       " [62],\n",
       " [64],\n",
       " [72],\n",
       " [69],\n",
       " [42],\n",
       " [48],\n",
       " [32],\n",
       " [68],\n",
       " [62],\n",
       " [53],\n",
       " [46],\n",
       " [51],\n",
       " [49],\n",
       " [120],\n",
       " [60],\n",
       " [65],\n",
       " [72],\n",
       " [59],\n",
       " [67],\n",
       " [25],\n",
       " [67],\n",
       " [41],\n",
       " [68],\n",
       " [56],\n",
       " [55],\n",
       " [78],\n",
       " [55],\n",
       " [39],\n",
       " [56],\n",
       " [74],\n",
       " [90],\n",
       " [61],\n",
       " [65],\n",
       " [66],\n",
       " [65],\n",
       " [86],\n",
       " [61],\n",
       " [72],\n",
       " [87],\n",
       " [48],\n",
       " [70],\n",
       " [27],\n",
       " [60],\n",
       " [53],\n",
       " [69],\n",
       " [38],\n",
       " [64],\n",
       " [57],\n",
       " [37],\n",
       " [52],\n",
       " [57],\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtd_caracteres =  Pipeline([\n",
    "                            ('qtd_caracteres', QtdCaracteres())\n",
    "                           ])\n",
    "qtd_caracteres.fit_transform(ds.noticia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureUnion([('text_process', text_process), \n",
    "                         ('qtd_palavras', qtd_palavras),\n",
    "                         ('qtd_caracteres', qtd_caracteres),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiza a lista de transformadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text_process', Pipeline(memory=None,\n",
       "       steps=[('count', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None))])),\n",
       " ('qtd_palavras',\n",
       "  Pipeline(memory=None, steps=[('qtd_palavras', QtdPalavras())])),\n",
       " ('qtd_caracteres',\n",
       "  Pipeline(memory=None, steps=[('qtd_caracteres', QtdCaracteres())]))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.transformer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline que encapsulará tudo isso para então avaliar esse novo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_features_2 = Pipeline([\n",
    "    ('features',features),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito     negativo   neutro   positivo   All\n",
      "Real                                          \n",
      " negativo        519        5        222   746\n",
      " neutro          106       73        273   452\n",
      " positivo        112       18        795   925\n",
      "All              737       96       1290  2123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6533421498283076"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avalia_modelo(pip_features_2,ds.noticia,ds.sentimento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode ver o modelo com a feature quantidade de caracteres ficou ainda pior.\n",
    "\n",
    "Menos 1% na acurácia, e a classificação da classe negativo e neutro piorou muito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF nos títulos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2123x3803 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17325 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "text_process = Pipeline([\n",
    "                ('counts', CountVectorizer()),\n",
    "                ('tf-idf', TfidfTransformer())\n",
    "               ])\n",
    "text_process.fit_transform(ds.noticia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureUnion([('text_process', text_process), \n",
    "                         ('qtd_palavras', qtd_palavras),\n",
    "                         ('qtd_caracteres', qtd_caracteres),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos agora como ficou o nosso objeto FeatureUnion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text_process', Pipeline(memory=None,\n",
       "       steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)), ('tf-idf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True))])),\n",
       " ('qtd_palavras',\n",
       "  Pipeline(memory=None, steps=[('qtd_palavras', QtdPalavras())])),\n",
       " ('qtd_caracteres',\n",
       "  Pipeline(memory=None, steps=[('qtd_caracteres', QtdCaracteres())]))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.transformer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_features_3 = Pipeline([\n",
    "    ('features',features),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito     negativo   neutro   positivo   All\n",
      "Real                                          \n",
      " negativo        293        0        453   746\n",
      " neutro           53        5        394   452\n",
      " positivo         40        0        885   925\n",
      "All              386        5       1732  2123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5572387331759703"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avalia_modelo(pip_features_3,ds.noticia,ds.sentimento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia de 56% essa até agora foi a pior.... =("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing por Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando os pacotes\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30434783],\n",
       "       [0.30434783],\n",
       "       [0.30434783],\n",
       "       ...,\n",
       "       [0.39130435],\n",
       "       [0.13043478],\n",
       "       [0.43478261]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando os pipelines:\n",
    "qtd_palavras =  Pipeline([\n",
    "                ('qtd_palavras', QtdPalavras()),\n",
    "                ('Scaler', MinMaxScaler())\n",
    "            ])\n",
    "qtd_palavras.fit_transform(ds.noticia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38583758],\n",
       "       [-0.06306401],\n",
       "       [-0.51196561],\n",
       "       ...,\n",
       "       [ 0.61028838],\n",
       "       [-1.07309261],\n",
       "       [ 1.84476778]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MinMaxScaler \n",
    "qtd_caracteres =  Pipeline([\n",
    "                ('qtd_caracteres', QtdCaracteres()),\n",
    "                ('Scaler', StandardScaler())\n",
    "            ])\n",
    "qtd_caracteres.fit_transform(ds.noticia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureUnion([('text_process', text_process), \n",
    "                         ('qtd_palavras', qtd_palavras),\n",
    "                         ('qtd_caracteres', qtd_caracteres),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text_process', Pipeline(memory=None,\n",
       "       steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)), ('tf-idf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True))])),\n",
       " ('qtd_palavras',\n",
       "  Pipeline(memory=None, steps=[('qtd_palavras', QtdPalavras())])),\n",
       " ('qtd_caracteres',\n",
       "  Pipeline(memory=None, steps=[('qtd_caracteres', QtdCaracteres())]))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vamos combinar tudo isso.\n",
    "features.transformer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importa o algoritmo SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_features_4 = Pipeline([\n",
    "    ('features',features),\n",
    "    ('classifier', SVC(kernel='linear')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito     negativo   neutro   positivo   All\n",
      "Real                                          \n",
      " negativo        535       48        163   746\n",
      " neutro          117      155        180   452\n",
      " positivo        122       61        742   925\n",
      "All              774      264       1085  2123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6745319910584484"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos então avaliar o modelo usando o SVM:\n",
    "avalia_modelo(pip_features_4,ds.noticia,ds.sentimento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse foi o que teve melhor acurácia! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
